
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-iYQeCzEYFbKjA/T2uDLTpkwGzCiq6soy8tYaI1GyVh/UjpbCx/TYkiZhlZB6+fzT" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="styles.css" />

    <title>NullTextforCartoon</title>
  </head>
  <body>
    <div style="padding: 2rem 0; background-color: #fff;">
<!--       <h1 style="text-align: center;">NullTextforCartoon</h1> -->
<!--       <h1 style="text-align: center;"><img style="width: 15%" src='./static/logo.png'></h1>  -->
      <h2 style="text-align: center;">Null-text Guidance in Diffusion Models is Secretly a Cartoon-style Creator</h2>
<!--       <h2 style="text-align: center;">by Fusing Diffusion Models</h2> -->
    </div>
    
    
    
<!--     <div class="container" style="max-width: 840px;">
                <div class="row">
                    <div class="col-md author"><a href="https://chenhsuanlin.bitbucket.io/" target="_blank">Chen-Hsuan Lin</a>*</div>
                    <div class="col-md author"><a href="https://www.cs.toronto.edu/~jungao/" target="_blank">Jun Gao</a>*</div>
                    <div class="col-md author"><a href="http://lumingtang.info" target="_blank">Luming Tang</a>*</div>
                    <div class="col-md author"><a href="https://tovacinni.github.io" target="_blank">Towaki Takikawa</a>*</div>
                    <div class="col-md author"><a href="https://www.cs.utoronto.ca/~xiaohui/" target="_blank">Xiaohui Zeng</a>*</div>
                </div>

                <div class="row">
                    <div class="col-md author"><a href="https://xunhuang.me" target="_blank">Xun Huang</a></div>
                    <div class="col-md author"><a href="https://karstenkreis.github.io/" target="_blank">Karsten Kreis</a></div>
                    <div class="col-md author"><a href="https://www.cs.utoronto.ca/~fidler/" target="_blank">Sanja Fidler</a><sup>†</sup></div>
                    <div class="col-md author"><a href="http://mingyuliu.net/" target="_blank">Ming-Yu Liu</a><sup>†</sup></div>
                    <div class="col-md author"><a href="https://tsungyilin.info" target="_blank">Tsung-Yi Lin</a></div>
                </div>

                <div class="row" style="margin-top:0.5rem; margin-left: auto; margin-right: auto;">
                    <div class="col-md">
                        <h9>*<sup>†</sup> : equal contributions</h9>
                        <div id="affiliation">NVIDIA Corporation</div>
                    </div>
                </div>
    </div> -->

    <div class="authors">
      <p style="padding-bottom: 5px;">Anonymous authors</p>
      <!-- <p class="smaller">Institute of Software, Chinese Academy of Sciences; University of Chinese Academy of Sciences; JD Explore Academy</p>  -->
    </div> 
    <div align="center" style="text-align: center; padding: 20px 100px; background-color: #fff;">
<!--       <embed src="./static/figure1_final.pdf" type="application/pdf" width="100%" height="100%" internalinstanceid="81 /> -->
      <object type="image/jpeg" data="./static/figure1.png" width=1200px height="100%" ></object>
    </div>
    
    <div class="authors" style="text-align: center!important; font-family: 'Noto Sans', sans-serif; margin:30px">
      <span class="link-block" style="font-style: inherit;font-weight: inherit;background-color: #dee2e6; padding: 10px 30px; border-radius: 25px;text-align: center;margin-right: 20px;">
         <a href="static/homepage.pdf" target="_blank"
                  class="external-link button is-normal is-rounded">
                  <span class="icon">
                    <i class="fas fa-book-reader"></i>
                  </span>
                  <span>Paper</span>
                </a>
      </span>
      <span class="link-block" style="font-style: inherit;font-weight: inherit;background-color: #dee2e6; padding: 10px 30px; border-radius: 25px;text-align: center;">
                <a href="https://github.com/NullTextforCartoon/NullTextforCartoon" target="_blank"
                class="external-link button is-normal is-rounded">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>
              </span>
    </div>
  

    <div class="abstract">
      <div class="inside">
        <h3 style="text-align: center;">Abstract</h2>
        <p class="text">
Classifier-free guidance is an effective sampling technique in diffusion models that has been widely adopted. The main idea is to extrapolate the model in the direction of text guidance and away from null-text guidance. In this paper, we demonstrate that null-text guidance in diffusion models is secretly a cartoon-style creator, i.e., the generated images can be efficiently transformed into cartoons by simply perturbing the null-text guidance. 
Specifically, we proposed two disturbance methods, i.e., Rollback disturbance (Back-D) and Image disturbance (Image-D), to construct misalignment between the noisy images used for predicting null-text guidance and text guidance (subsequently referred to as \textbf{null-text noisy image} and \textbf{text noisy image} respectively) in the sampling process. 
Back-D achieves cartoonization by altering the noise level of null-text noisy image via replacing $x_t$ with $x_{t+\Delta t}$.
Image-D, alternatively, produces high-fidelity, diverse cartoons by defining $x_t$ as a clean input image, which further improves the incorporation of finer image details.
Through comprehensive experiments, we delved into the principle of noise disturbing for null-text and uncovered that the efficacy of disturbance depends on the correlation between the null-text noisy image and the source image. Moreover, our proposed techniques, which can generate cartoon images and cartoonize specific ones, are training-free and easily integrated as a plug-and-play component in any classifier-free guided diffusion model.
Project page is available at \url{https://nulltextforcartoon.github.io/}.
        </p>
<!--         <br>
        <br> 
        <a class="read-paper" href="https://arxiv.org/pdf/2211.14108.pdf" target="_blank"><button>Research Paper</button></a>   -->
      </div>
    </div>
    
    <div style="padding: 50px;background-color: rgb(230, 230, 230);color:black; text-align: center;">
      <h2>An overview of our Saiency-aware Noise Blending.</h2>
    </div>
     <div style="text-align: center; padding:50px 100px; background-color: #fff; font-size:20px">
        <!-- <h3 style="text-align: center;"></h5> -->
      <video autoplay loop muted style="max-width: 60vw;"><source type="video/mp4" src="./static/method_show2.mp4"></video>
       <p style="text-align: center;">An overview of our Saiency-aware Noise Blending. Given two diffusion models, we first design a ''Noise to salience map'' module to  obtain salience maps. After that, we can generate saliency-aware masks based on the salience maps. Finally, we blend the diffusion models in the noise space according to the mask. (*) classifier-free guidances are noises instead of noisy images, and we add the image here just for visualization.</p>
    </div>
    
    
    <div style="padding: 50px;background-color: rgb(230, 230, 230);color:black; text-align: center;">
      <h2>Fine-grained Fusion</h2>
    </div>
    <div style="text-align: center; padding: 0; background-color: #fff;">
      <video autoplay loop muted style="max-width: 60vw;"><source type="video/mp4" src="./static/car_show3.mp4"></video>
    </div>
    
    <div style="padding: 50px;background-color: rgb(230, 230, 230);color:black; text-align: center;">
      <h2>Recontextualization</h2>
    </div>
    <div style="text-align: center; padding: 0; background-color: #fff;">
      <video autoplay loop muted style="max-width: 60vw;"><source type="video/mp4" src="./static/dreambooth_show.mp4"></video>
    </div>
    
    <div style="padding: 50px;background-color: rgb(230, 230, 230);color:black; text-align: center;">
      <h2>Cross-domain Fusion</h2>
    </div>
    <div style="text-align: center; padding: 0; background-color: #fff;">
      <video autoplay loop muted style="max-width: 60vw;"><source type="video/mp4" src="./static/cartoon_show2.mp4"></video>
    </div>
    
    <div style="padding: 50px;background-color: rgb(230, 230, 230);color:black; text-align: center;">
      <h2>Displaying more experimental results.</h2>
    </div>
    <div align="center" style="text-align: center; padding: 20px 100px; background-color: #fff;">
      <h3 style="text-align:center;padding: 20px; margin-top: 20px;">Fine-grained Fusion</h3>
      <object type="image/jpeg" data="./static/car_show.jpg" width="90%" height="80%" ></object>
       <h3 style="text-align:center;padding: 20px; margin-top: 20px;">Recontextualization</h3>
      <object type="image/jpeg" data="./static/dreambooth_show.jpg" width="90%" height="80%" ></object>
       <h3 style="text-align:center;padding: 20px; margin-top: 20px;">Cross-domain Fusion</h3>
      <object type="image/png" data="./static/homepage_cartoon.png" width="90%" height="80%" ></object>
    </div>
    
   

<!--    <div class="white">
      <figure class="sampler">
         <div align="center"><object type="image/jpeg" data="./static/method.jpg" width="90%" height="80%" ></object>
        </div>
       <figcaption><p> xxx</p></figcaption>
      </figure>

    </div>  -->
<!--     <div class="container">
            <div id="citation">
                waiting。。。。。
            </div>
     </div> -->


    <!-- <div class="authors">
      <p style="padding-bottom: 25px;">Daniel Watson, William Chan, Ricardo Martin-Brualla, Jonathan Ho, Andrea Tagliasacchi, Mohammad Norouzi</p>
      <p class="smaller">Google Research</p>
    </div> -->

<!--     <div class="thanks">
      <h1>Special Thanks</h1>
      <br>
      <p class="smaller" style="text-align: justify;">We would like to thank Ben Poole for thoroughly reviewing this work, and providing useful feedback and ideas since the earliest stages of our research. We thank Tim Salimans for providing us with stable code to train diffusion models, which we used as the starting point for this paper, as well as code for neural network modules and diffusion sampling tricks used in their more recent "Video Diffusion Models" paper. We thank Erica Moreira for her critical support on juggling resource allocations for us to execute our work. We also thank David Fleet for his key support on securing the computational resources required for our work, as well as the many helpful research discussions throughout. We additionally would like to acknowledge and thank Kai-En Lin and Vincent Sitzmann for providing us with the outputs of their work on novel view synthesis and their helpful correspondence. We thank Mehdi Sajjadi and Etienne Pot for consistently lending us their expertise, especially on issues with datasets, cameras, rays, and all-things 3D. We thank Keunhong Park, who refactored a lot of the NeRF code we used, which made it easier to implement our proposed 3D consistency evaluation scheme. We thank Sarah Laszlo for helping us ensure our models and datasets meet responsible AI practices. Finally, we'd like to thank Geoffrey Hinton, Chitwan Saharia, and more widely the Google Brain Toronto team for their useful feedback, suggestions, and ideas throughout our research effort.</p>
    </div> -->

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-u1OknCvxWvY5kfmNBILK2hRnQC3Pr17a+RTT6rIHI7NnikvbZlHgTPOOmMi466C8" crossorigin="anonymous"></script>
  </body>
</html>
